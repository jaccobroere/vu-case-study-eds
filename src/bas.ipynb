{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VU Econometics and Data Science: Case Study\n",
    "```\n",
    "Author(s): Jacco Broere\n",
    "```\n",
    "\n",
    "\n",
    "### Setup\n",
    "- Setup config.ini file\n",
    "- Install necessary packages\n",
    "- Download and unpack data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper functions\n",
    "from helpers.helper_functions import transform_data, add_actuals\n",
    "from helpers.helper_classes import AddFeatureNames\n",
    "\n",
    "# sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# feature_engine\n",
    "from feature_engine.selection import DropFeatures, DropConstantFeatures, DropDuplicateFeatures\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "if os.path.isfile('src/config.ini'):\n",
    "    config.read('src/config.ini')\n",
    "elif os.path.isfile('config.ini'):\n",
    "    config.read('config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "raw_train = pd.read_csv(config['PATH']['RAW_TRAIN_DATA'])\n",
    "raw_test = pd.read_csv(config['PATH']['RAW_TEST_DATA'])\n",
    "actuals = pd.read_csv(config['PATH']['ACTUALS'])\n",
    "raw_total = pd.concat([raw_train, raw_test], axis=1)\n",
    "\n",
    "# Read parameters\n",
    "SEED = config.getint('PARAMS', 'SEED')\n",
    "N_COMPONENTS = config.getint('PARAMS', 'N_COMPONENTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to accesible format and add actuals\n",
    "train = transform_data(raw_train)\n",
    "train = add_actuals(train, actuals)\n",
    "test = transform_data(raw_test)\n",
    "test = add_actuals(test, actuals)\n",
    "total = transform_data(raw_total)\n",
    "total = add_actuals(total, actuals)\n",
    "\n",
    "# get target variable\n",
    "y_train = train[\"cancer\"]\n",
    "y_test = test[\"cancer\"]\n",
    "y_total = total[\"cancer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipe = Pipeline([\n",
    "    # Step 0:\n",
    "        # Drop constant and duplicate features\n",
    "        ('drop_features', DropFeatures(features_to_drop=[\"cancer\"])),\n",
    "        ('drop_constant', DropConstantFeatures(tol=0.98)),\n",
    "    # Step 1:\n",
    "        # Apply scaling to data as it is a requirement for the variance maximization procedure of PCA\n",
    "        ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "X_train = preprocessing_pipe.fit_transform(train)\n",
    "X_test = preprocessing_pipe.fit_transform(test)\n",
    "X_total = preprocessing_pipe.fit_transform(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipe(clf, shrink_method='None', n=N_COMPONENTS):\n",
    "    \n",
    "    drop_constant = DropConstantFeatures(tol=0.98)\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=n)\n",
    "    spca = SparsePCA(n_components=n)\n",
    "    add_features_names = AddFeatureNames(prefix=\"cmpnt_\")\n",
    "\n",
    "    if shrink_method == 'PCA':\n",
    "        combined_features = FeatureUnion([(\"drop_constant\", drop_constant), \n",
    "                                          (\"scaler\", scaler), \n",
    "                                          (\"pca\", pca),\n",
    "                                          (\"add_features_names\", add_features_names)])\n",
    "        \n",
    "    elif shrink_method == 'SPCA':\n",
    "        combined_features = FeatureUnion([(\"drop_constant\", drop_constant), \n",
    "                                          (\"scaler\", scaler), \n",
    "                                          (\"spca\", spca),\n",
    "                                          (\"add_features_names\", add_features_names)])\n",
    "        \n",
    "    elif shrink_method == 'None':\n",
    "        combined_features = FeatureUnion([(\"drop_constant\", drop_constant), \n",
    "                                          (\"scaler\", scaler), \n",
    "                                          (\"add_features_names\", add_features_names)])\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Input valid shrinking method from: {PCA, SPCA, None}\")\n",
    "\n",
    "        \n",
    "    pipeline = Pipeline([(\"features\", combined_features), \n",
    "                         (\"clf\", clf)])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_COMPONENTS = 10, SEED = 2023, CV = 5\n",
      "--------------------------------------------------------------------\n",
      "None\n",
      "--------------------------------------------------------------------\n",
      "KNeighbors : Mean Accuracy: 0.790 and Standard Deviation: (0.103) and Runtime: 7.592 s\n",
      "RandomForest : Mean Accuracy: 0.971 and Standard Deviation: (0.035) and Runtime: 7.260 s\n",
      "LogisticReg : Mean Accuracy: 0.943 and Standard Deviation: (0.083) and Runtime: 7.101 s\n",
      "LGBMClassifier : Mean Accuracy: 0.945 and Standard Deviation: (0.053) and Runtime: 17.069 s\n",
      "--------------------------------------------------------------------\n",
      "PCA\n",
      "--------------------------------------------------------------------\n",
      "KNeighbors : Mean Accuracy: 0.790 and Standard Deviation: (0.103) and Runtime: 10.258 s\n",
      "RandomForest : Mean Accuracy: 0.929 and Standard Deviation: (0.111) and Runtime: 6.851 s\n",
      "LogisticReg : Mean Accuracy: 0.943 and Standard Deviation: (0.083) and Runtime: 6.390 s\n",
      "LGBMClassifier : Mean Accuracy: 0.945 and Standard Deviation: (0.053) and Runtime: 12.730 s\n",
      "--------------------------------------------------------------------\n",
      "SPCA\n",
      "--------------------------------------------------------------------\n",
      "KNeighbors : Mean Accuracy: 0.790 and Standard Deviation: (0.103) and Runtime: 59.819 s\n",
      "RandomForest : Mean Accuracy: 0.929 and Standard Deviation: (0.111) and Runtime: 63.601 s\n",
      "LogisticReg : Mean Accuracy: 0.943 and Standard Deviation: (0.083) and Runtime: 61.811 s\n",
      "LGBMClassifier : Mean Accuracy: 0.945 and Standard Deviation: (0.053) and Runtime: 66.598 s\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = {'KNeighbors' : KNeighborsClassifier(),\n",
    "          'RandomForest' : RandomForestClassifier(random_state=SEED),\n",
    "          'LogisticReg' : LogisticRegression(random_state=SEED),\n",
    "          'LGBMClassifier': LGBMClassifier(random_state=SEED)\n",
    "          }\n",
    "folds=5\n",
    "\n",
    "def run_models(shrink: str, cv=folds):\n",
    "    for name, model, in models.items():\n",
    "        start = time.time()\n",
    "        clf = model\n",
    "        pipeline = create_pipe(clf, shrink_method=shrink, n=2)\n",
    "        scores = cross_val_score(pipeline, \n",
    "                                 X_total,\n",
    "                                 y_total,\n",
    "                                 scoring='accuracy', \n",
    "                                 cv=cv, n_jobs=5, \n",
    "                                 error_score='raise')\n",
    "        print(name, ': Mean Accuracy: %.3f and Standard Deviation: (%.3f) and Runtime: %.3f s' % (np.mean(scores), np.std(scores), time.time() - start))\n",
    "\n",
    "print(f'N_COMPONENTS = {N_COMPONENTS}, SEED = {SEED}, CV = {folds}')\n",
    "print(68 * '-')\n",
    "print('None')\n",
    "print(68 * '-')\n",
    "run_models(shrink='None')\n",
    "print(68 * '-')\n",
    "print('PCA')\n",
    "print(68 * '-')\n",
    "run_models(shrink='PCA')\n",
    "print(68 * '-')\n",
    "print('SPCA')\n",
    "print(68 * '-')\n",
    "run_models(shrink='SPCA')\n",
    "print(68 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(parameters, X, y, pipeline):\n",
    "\n",
    "    grid = GridSearchCV(pipeline, \n",
    "                        parameters, \n",
    "                        scoring='accuracy', \n",
    "                        n_jobs=1, \n",
    "                        cv=3, \n",
    "                        error_score='raise')\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    return grid\n",
    "\n",
    "# clf = LogisticRegression(random_state=SEED)\n",
    "# pipeline = create_pipe(clf, shrink_method='PCA')\n",
    "\n",
    "# param_grid = dict(features__pca__n_components = list(range(1,10)),\n",
    "#                  clf__C = [0.1, 1.0, 10, 100],\n",
    "#                  clf__solver = ['liblinear', 'saga'],\n",
    "#                  clf__penalty = ['l2', 'l1'])\n",
    "\n",
    "# grid = get_params(param_grid, X_train, y_train, pipeline)\n",
    "\n",
    "# print(\"Best cross-validation accuracy: {:.3f}\".format(grid.best_score_))\n",
    "# print(\"Test set score: {:.3f}\".format(grid.score(X_test, y_test))) \n",
    "# print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "92d3ca18b4289e5a59092b5e555528d322048c59e12087c1ad117261a9f3261c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
