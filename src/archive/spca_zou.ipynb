{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# import utility modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "# import optuna\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# helper functions and classes\n",
    "from helpers.helper_functions import transform_data, add_actuals\n",
    "from helpers.helper_classes import AddFeatureNames, Gene_SPCA, EnetSPCA\n",
    "\n",
    "# sklearn\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_auc_score, roc_curve, RocCurveDisplay, f1_score\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# feature_engine\n",
    "from feature_engine.selection import DropFeatures, DropConstantFeatures, DropDuplicateFeatures\n",
    "\n",
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# Read data\n",
    "data = load(config['PATH']['DATA_DIR'] + '/microarray-data-dict.lib')\n",
    "\n",
    "# Read parameters\n",
    "SEED = config.getint('PARAMS', 'SEED')\n",
    "N_COMPONENTS = config.getint('PARAMS', 'N_COMPONENTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress based on max iterations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/10000 [01:07<2:40:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897, Nonzero Percent: 0.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/casparhentenaar/Library/CloudStorage/OneDrive-VrijeUniversiteitAmsterdam/VU Master/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_testing = data['sorlie']['none']['X_train']\n",
    "X_testing_test = data['sorlie']['none']['X_test']\n",
    "\n",
    "spca = EnetSPCA(n_comps = 5, alpha = 0.05, tol = 0.0001, use_sklearn= True, n_jobs = 6)\n",
    "spca.fit(X_testing, verbose = 1)\n",
    "\n",
    "X_transformed_train = spca.transform(X_testing)\n",
    "X_transformed_test = spca.transform(X_testing_test)\n",
    "\n",
    "y_train = data['sorlie']['none']['y_train']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_transformed_train, y_train)\n",
    "\n",
    "acc = lr.score(X_transformed_test, data['sorlie']['none']['y_test'])\n",
    "nzero_percent = spca.nonzero / spca.totloadings\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}, Nonzero Percent: {nzero_percent:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only count accuracy wins first\n",
    "def list_transforms_metrics(results_dict):\n",
    "    metrics = []\n",
    "    transform_win_counter = {}\n",
    "    hasRun = False\n",
    "    for dname, dobj in results_dict.items():\n",
    "        for clf_name, clf_obj in dobj.items():\n",
    "            for tname, tobj in clf_obj.items():\n",
    "                if tname not in transform_win_counter:\n",
    "                    transform_win_counter[tname] = 0\n",
    "                for metric_name, metric in tobj.items():\n",
    "                    if metric_name not in metrics:\n",
    "                        metrics.append(metric_name)\n",
    "    return transform_win_counter, metrics\n",
    "\n",
    "counter, metrics = list_transforms_metrics(results_dict)\n",
    "\n",
    "counter\n",
    "\n",
    "count_results = {}\n",
    "# Loop over metrics found in results dictionary\n",
    "for metric in metrics:\n",
    "    count_results[metric] = counter.copy()\n",
    "    cur_counter = count_results[metric]\n",
    "    cur_counter['ties'] = 0\n",
    "    for dname, dobj in results_dict.items():\n",
    "        for clf_name, clf_obj in dobj.items():\n",
    "            # if clf_name != 'knn':\n",
    "            #     continue\n",
    "            cur_max = 0\n",
    "            for tname, tobj in clf_obj.items():\n",
    "                if tobj[metric] > cur_max:\n",
    "                    cur_max = tobj[metric]\n",
    "                    max_tname = tname\n",
    "                elif tobj[metric] == cur_max:\n",
    "                    max_tname = ''\n",
    "            if max_tname == '':\n",
    "                cur_counter['ties'] += 1\n",
    "                continue\n",
    "            cur_counter[max_tname] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  none &  pca &  spca &  ties \\\\\n",
      "\\midrule\n",
      "Accuracy  &    23 &   13 &    11 &    41 \\\\\n",
      "F1        &    30 &   13 &    14 &    31 \\\\\n",
      "Recall    &    28 &   13 &    13 &    34 \\\\\n",
      "Precision &    29 &   15 &    13 &    31 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/vzrcysld109_2gh3z360j7x00000gn/T/ipykernel_92996/2664355936.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.to_latex())\n"
     ]
    }
   ],
   "source": [
    "count_results\n",
    "\n",
    "#Print count results to pandas dataframe\n",
    "df = pd.DataFrame(count_results)\n",
    "df.columns = ['Accuracy', 'F1', 'Recall', 'Precision']\n",
    "df = df.T\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e6bfdc5e747882d0c1236e11db0a3029a2ad21f412da50d5656bcce3e752b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
