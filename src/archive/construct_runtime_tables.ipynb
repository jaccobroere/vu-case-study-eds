{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# helper functions\n",
    "from helpers.helper_classes import Gene_SPCA, EnetSPCA\n",
    "\n",
    "# sklearn\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "# joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# Read parameters\n",
    "SEED = config.getint('PARAMS', 'SEED')\n",
    "N_COMPONENTS = config.getint('PARAMS', 'N_COMPONENTS')\n",
    "\n",
    "# Load in data\n",
    "data = load(config['PATH']['DATA_DIR'] + '/microarray-data-dict.lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant transformations\n",
    "    # TODO: make spca and gene spca a fair comparison by making them use \n",
    "    # the same number of non-zero loadings\n",
    "\n",
    "def get_gene_spca(n_components, random_state, alpha = 10):\n",
    "    return Gene_SPCA(n_comps = n_components, l1= alpha)\n",
    "\n",
    "def get_spca(n_components, random_state, alpha = 0.001):\n",
    "    return EnetSPCA(n_comps=n_components, alpha = alpha, tol = 0.001, n_jobs = 6)\n",
    "\n",
    "def get_pca(n_components, random_state):\n",
    "    return PCA(n_components=n_components, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config for runtime tables\n",
    "\n",
    "## Which datasets to run\n",
    "\n",
    "# Golub because original, Christensen because of small dataset, Chin because of large dataset, Nakayama because of large number of classes\n",
    "# dataset_list = ['golub', 'christensen', 'chin', 'nakayama']\n",
    "\n",
    "# Easy running datasets\n",
    "# dataset_list = ['sorlie', 'christensen', 'alon']\n",
    "# datasets = ['chin', 'chowdary', 'gravier', 'west']\n",
    "datasets = ['sorlie', 'christensen']\n",
    "\n",
    "## Which transformations to run\n",
    "transforms_dict = {'pca': get_pca, 'spca': get_gene_spca, 'gene_spca': get_gene_spca}\n",
    "\n",
    "## Parameter settings\n",
    "n_components_list = [5]\n",
    "# percentage_nzero_loadings = [0.2]\n",
    "fixed_alpha = None#{'spca': 40, 'gene_spca': 20}\n",
    "N_TIMINGS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bisection search for regularization parameter that sets nonzero loadings to a certain percentage\n",
    "def get_regularisation_value(X, n_components, percentage_nzero_loadings, get_transform, lower_bound = 0.0001, upper_bound = 1000, verbose = 0):\n",
    "    percent_nz = 0\n",
    "    alpha_cur = 0\n",
    "    alpha_lower = lower_bound\n",
    "    alpha_upper = upper_bound\n",
    "    \n",
    "    while abs(percent_nz - percentage_nzero_loadings) > 0.02:\n",
    "        if upper_bound - alpha_lower < 0.001:\n",
    "            raise ValueError(\"Correct alpha likely not in interval\")\n",
    "\n",
    "        alpha_cur = (alpha_lower + alpha_upper) / 2\n",
    "        cur_transform = get_transform(alpha = alpha_cur, n_components = n_components, random_state = SEED)\n",
    "        cur_transform.fit(X)\n",
    "        percent_nz = cur_transform.nonzero / cur_transform.totloadings\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"lower: {alpha_lower}, upper: {alpha_upper}, cur: {alpha_cur}\")\n",
    "            print(f\"percentage nonzero: {percent_nz}\")\n",
    "            print('-' * 40)\n",
    "\n",
    "        if percent_nz > percentage_nzero_loadings:\n",
    "            alpha_lower = alpha_cur\n",
    "        else:\n",
    "            alpha_upper = alpha_cur\n",
    "    return alpha_cur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Dataset: sorlie, n_components: 5\n",
      "non zero % target: 0.19210526315789472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<04:18, 38.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower: 0, upper: 4000, cur: 2000.0\n",
      "percentage nonzero: 0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<54:40,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower: 0, upper: 2000.0, cur: 1000.0\n",
      "percentage nonzero: 0.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/10000 [00:00<00:55, 178.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower: 0, upper: 1000.0, cur: 500.0\n",
      "percentage nonzero: 0.02587719298245614\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/10000 [00:00<01:48, 91.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower: 0, upper: 500.0, cur: 250.0\n",
      "percentage nonzero: 0.19429824561403508\n",
      "----------------------------------------\n",
      "Timing pca...\n",
      "Timing spca...\n",
      "Timing gene spca...\n",
      "----------------------------------------\n",
      "Dataset: christensen, n_components: 5\n",
      "non zero % target: 0.1578202406227884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/10000 [00:00<01:38, 101.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower: 0, upper: 4000, cur: 2000.0\n",
      "percentage nonzero: 0.15003538570417552\n",
      "----------------------------------------\n",
      "Timing pca...\n",
      "Timing spca...\n",
      "Timing gene spca...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dict = {}\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    for dname in datasets:\n",
    "        print('-' * 40)\n",
    "        print(f\"Dataset: {dname}, n_components: {n_components}\")\n",
    "        \n",
    "        X_cur = data[dname]['none']['X_train']\n",
    "            \n",
    "        spca_transform = get_spca(n_components = n_components, random_state = SEED, alpha = 0.01)\n",
    "        spca_fitted = spca_transform.fit(X_cur)\n",
    "        spca_nzero_percentage = spca_fitted.nonzero / spca_fitted.totloadings\n",
    "        print(f\"non zero % target: {spca_nzero_percentage}\")\n",
    "\n",
    "        # Find lambda value such that gene_spca has same percentage of nonzero loadings as spca.\n",
    "        lambda_genespca = get_regularisation_value(X_cur, n_components, spca_nzero_percentage, get_gene_spca, lower_bound = 0, upper_bound = X_cur.shape[1] * 4, verbose = 1)                 \n",
    "\n",
    "        # Time pca\n",
    "        print(f\"Timing pca...\")\n",
    "        results_dict[(dname, 'pca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_pca = get_pca(n_components = n_components, random_state = SEED)\n",
    "            start = time.time()\n",
    "            cur_pca.fit(X_cur)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'pca', n_components)].append(end - start)\n",
    "\n",
    "        # Time spca\n",
    "        print(f\"Timing spca...\")\n",
    "        results_dict[(dname, 'spca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_spca = get_spca(n_components = n_components, random_state = SEED, alpha = 0.01)\n",
    "            start = time.time()\n",
    "            cur_spca.fit(X_cur)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'spca', n_components)].append(end - start)\n",
    "\n",
    "        # Time gene spca\n",
    "        print(f\"Timing gene spca...\")\n",
    "        results_dict[(dname, 'gene_spca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_genespca = get_gene_spca(n_components = n_components, random_state = SEED, alpha = lambda_genespca)\n",
    "            start = time.time()\n",
    "            cur_genespca.fit(X_cur)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'gene_spca', n_components)].append(end - start)\n",
    "\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        pca        spca  gene_spca\n",
      "sorlie      avg    0.133314   26.534121   0.024038\n",
      "            stdev  0.075122    0.808690   0.005266\n",
      "christensen avg    0.045619  160.145590   0.264853\n",
      "            stdev  0.016029    1.426293   0.035340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/vzrcysld109_2gh3z360j7x00000gn/T/ipykernel_35388/1127513334.py:25: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./logs/runtime_dict.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reform created dictionary into right format for dataframe\n",
    "reform = {}\n",
    "for n_components in n_components_list:\n",
    "    for dname in datasets:\n",
    "        reform[(dname, 'avg')] = []\n",
    "        reform[(dname, 'stdev')] = []\n",
    "        for tname in transforms_dict.keys():\n",
    "            res_arr = results_dict[(dname, tname, n_components)]\n",
    "            reform[(dname, 'avg')].append(np.mean(res_arr))\n",
    "            reform[(dname, 'stdev')].append(np.std(res_arr))\n",
    "\n",
    "    # Create dataframe\n",
    "    res_runtimes = pd.DataFrame.from_dict(reform).T\n",
    "    res_runtimes.columns = transforms_dict.keys()\n",
    "\n",
    "    # Save to file\n",
    "    fname = config['LOGGING']['TIME_DIR'] + f\"/runtime_table_{n_components}.txt\"\n",
    "\n",
    "    # If exists delete\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "\n",
    "    # Write table to file\n",
    "    with open(fname, 'a') as f:\n",
    "        f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n",
    "    print(res_runtimes)\n",
    "\n",
    "dump(results_dict, config['LOGGING']['TIME_DIR'] + f\"/runtime_dict.joblib\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/vzrcysld109_2gh3z360j7x00000gn/T/ipykernel_35388/1904901076.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n"
     ]
    }
   ],
   "source": [
    "# print(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n",
    "\n",
    "# Print above to file\n",
    "with open('runtime_table.txt', 'w') as f:\n",
    "    # res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\")\n",
    "    # append to file\n",
    "    f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logsruntime_table_christensen_5.txt\n"
     ]
    }
   ],
   "source": [
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Dataset: sorlie, n_components: 5\n",
      "non zero % target: 0.19210526315789472\n",
      "lower: 0, upper: 1824, cur: 912.0\n",
      "percentage nonzero: 0.0\n",
      "----------------------------------------\n",
      "lower: 0, upper: 912.0, cur: 456.0\n",
      "percentage nonzero: 0.038157894736842106\n",
      "----------------------------------------\n",
      "lower: 0, upper: 456.0, cur: 228.0\n",
      "percentage nonzero: 0.21842105263157896\n",
      "----------------------------------------\n",
      "lower: 228.0, upper: 456.0, cur: 342.0\n",
      "percentage nonzero: 0.11359649122807018\n",
      "----------------------------------------\n",
      "lower: 228.0, upper: 342.0, cur: 285.0\n",
      "percentage nonzero: 0.1631578947368421\n",
      "----------------------------------------\n",
      "lower: 228.0, upper: 285.0, cur: 256.5\n",
      "percentage nonzero: 0.1881578947368421\n",
      "----------------------------------------\n",
      "Timing pca...\n",
      "Timing spca...\n",
      "Timing gene spca...\n",
      "----------------------------------------\n",
      "Dataset: christensen, n_components: 5\n",
      "non zero % target: 0.1578202406227884\n",
      "lower: 0, upper: 5652, cur: 2826.0\n",
      "percentage nonzero: 0.09072894550601557\n",
      "----------------------------------------\n",
      "lower: 0, upper: 2826.0, cur: 1413.0\n",
      "percentage nonzero: 0.24147204529370134\n",
      "----------------------------------------\n",
      "lower: 1413.0, upper: 2826.0, cur: 2119.5\n",
      "percentage nonzero: 0.1372965322009908\n",
      "----------------------------------------\n",
      "lower: 1413.0, upper: 2119.5, cur: 1766.25\n",
      "percentage nonzero: 0.18343949044585986\n",
      "----------------------------------------\n",
      "lower: 1766.25, upper: 2119.5, cur: 1942.875\n",
      "percentage nonzero: 0.15767869780608634\n",
      "----------------------------------------\n",
      "Timing pca...\n",
      "Timing spca...\n",
      "Timing gene spca...\n",
      "                        pca        spca  gene_spca\n",
      "sorlie      avg    0.038943   21.247837   0.025298\n",
      "            stdev  0.009469    0.608421   0.001631\n",
      "christensen avg    0.041918  161.660333   0.569928\n",
      "            stdev  0.017568    6.710147   0.034973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/vzrcysld109_2gh3z360j7x00000gn/T/ipykernel_42979/283148652.py:132: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./logs/times//runtime_dict.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "##### 1.0 IMPORT MODULES\n",
    "################################################################################\n",
    "# import utility modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "import time\n",
    "\n",
    "# helper functions\n",
    "from helpers.helper_classes import Gene_SPCA, EnetSPCA\n",
    "from helpers.helper_functions import get_regularisation_value\n",
    "\n",
    "# sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# Read parameters\n",
    "SEED = config.getint('PARAMS', 'SEED')\n",
    "\n",
    "# Load in data\n",
    "data = load(config['PATH']['DATA_DIR'] + '/microarray-data-dict.lib')\n",
    "\n",
    "# Relevant transformations\n",
    "def get_gene_spca(n_components, random_state, alpha = 10):\n",
    "    return Gene_SPCA(n_comps = n_components, l1= alpha, tol = 0.001)\n",
    "\n",
    "def get_spca(n_components, random_state, alpha = 0.001):\n",
    "    return EnetSPCA(n_comps=n_components, alpha = alpha, tol = 0.001)\n",
    "\n",
    "def get_pca(n_components, random_state):\n",
    "    return PCA(n_components=n_components, random_state=random_state)\n",
    "\n",
    "################################################################################\n",
    "##### 2.0 Config of plotting script\n",
    "################################################################################\n",
    "\n",
    "# Set datasets\n",
    "datasets = ['chin', 'chowdary', 'gravier', 'west']\n",
    "N_TIMINGS = 3\n",
    "n_components_list = [5]\n",
    "transforms_dict = {'pca': get_pca, 'spca': get_spca, 'gene_spca': get_gene_spca}\n",
    "datasets = ['sorlie', 'christensen']\n",
    "################################################################################\n",
    "##### 3.0 Obtain results\n",
    "################################################################################\n",
    "\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    for dname in datasets:\n",
    "        print('-' * 40)\n",
    "        print(f\"Dataset: {dname}, n_components: {n_components}\")\n",
    "        \n",
    "        X_cur = data[dname]['none']['X_train']\n",
    "            \n",
    "        spca_transform = get_spca(n_components = n_components, random_state = SEED, alpha = 0.01)\n",
    "        spca_fitted = spca_transform.fit(X_cur, n_jobs = 6)\n",
    "        spca_nzero_percentage = spca_fitted.nonzero / spca_fitted.totloadings\n",
    "        print(f\"non zero % target: {spca_nzero_percentage}\")\n",
    "\n",
    "        # Find lambda value such that gene_spca has same percentage of nonzero loadings as spca.\n",
    "        lambda_genespca = get_regularisation_value(X_cur, n_components, spca_nzero_percentage, get_gene_spca, lower_bound = 0, upper_bound = X_cur.shape[1] * 4, verbose = 1, random_state = SEED)                 \n",
    "\n",
    "        # Time pca\n",
    "        print(f\"Timing pca...\")\n",
    "        results_dict[(dname, 'pca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_pca = get_pca(n_components = n_components, random_state = SEED)\n",
    "            start = time.time()\n",
    "            cur_pca.fit(X_cur)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'pca', n_components)].append(end - start)\n",
    "\n",
    "        # Time spca\n",
    "        print(f\"Timing spca...\")\n",
    "        results_dict[(dname, 'spca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_spca = get_spca(n_components = n_components, random_state = SEED, alpha = 0.01)\n",
    "            start = time.time()\n",
    "            cur_spca.fit(X_cur, n_jobs = 6)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'spca', n_components)].append(end - start)\n",
    "\n",
    "        # Time gene spca\n",
    "        print(f\"Timing gene spca...\")\n",
    "        results_dict[(dname, 'gene_spca', n_components)] = []\n",
    "        for i in range(N_TIMINGS):\n",
    "            cur_genespca = get_gene_spca(n_components = n_components, random_state = SEED, alpha = lambda_genespca)\n",
    "            start = time.time()\n",
    "            cur_genespca.fit(X_cur)\n",
    "            end = time.time()\n",
    "            results_dict[(dname, 'gene_spca', n_components)].append(end - start)\n",
    "\n",
    "                \n",
    "################################################################################\n",
    "##### 4.0 Save results to table\n",
    "################################################################################\n",
    "            \n",
    "reform = {}\n",
    "for n_components in n_components_list:\n",
    "    for dname in datasets:\n",
    "        reform[(dname, 'avg')] = []\n",
    "        reform[(dname, 'stdev')] = []\n",
    "        for tname in transforms_dict.keys():\n",
    "            res_arr = results_dict[(dname, tname, n_components)]\n",
    "            reform[(dname, 'avg')].append(np.mean(res_arr))\n",
    "            reform[(dname, 'stdev')].append(np.std(res_arr))\n",
    "\n",
    "    # Create dataframe\n",
    "    res_runtimes = pd.DataFrame.from_dict(reform).T\n",
    "    res_runtimes.columns = transforms_dict.keys()\n",
    "\n",
    "    # Save to file\n",
    "    fname = config['LOGGING']['TIME_DIR'] + f\"/runtime_table_{n_components}.txt\"\n",
    "\n",
    "    # If exists delete\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "\n",
    "    # Write table to file\n",
    "    with open(fname, 'a') as f:\n",
    "        f.write(res_runtimes.to_latex(caption = f\"Runtime for {dname} data, {n_components} components\", label = f\"tab:runtime_{dname}\"))\n",
    "    print(res_runtimes)\n",
    "\n",
    "dump(results_dict, config['LOGGING']['TIME_DIR'] + f\"/runtime_dict.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e6bfdc5e747882d0c1236e11db0a3029a2ad21f412da50d5656bcce3e752b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
