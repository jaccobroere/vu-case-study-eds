{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from helpers.helper_classes import AddFeatureNames, Gene_SPCA\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# Read data\n",
    "data = load(config['PATH']['DATA_DIR'] + '/microarray-data-dict.lib')\n",
    "\n",
    "# Read parameters\n",
    "SEED = config.getint('PARAMS', 'SEED')\n",
    "N_COMPONENTS = config.getint('PARAMS', 'N_COMPONENTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['golub']['none']['X_train']\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress based on max iterations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:59<00:00,  3.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Gene_SPCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Gene_SPCA</label><div class=\"sk-toggleable__content\"><pre>Gene_SPCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Gene_SPCA()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spca = Gene_SPCA()\n",
    "spca.fit(X, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 20)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre step 1: get and center data\n",
    "\n",
    "X = np.random.random((100,2000))\n",
    "mean_subtr = np.mean(X, axis = 0)\n",
    "\n",
    "# Important, center data\n",
    "X = X - mean_subtr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 1. General SPCA algorithm\n",
    "1. let A start at V[,1:k], the loadings of the first k ordinary principal components\n",
    "2. given A = [$\\alpha_1, \\cdots, \\alpha_k$] solve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Gene_SPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_comps = 20, max_iter = 200, tol = 0.001, improve_tol = 0.00001, l1 = 5):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.improve_tol = improve_tol\n",
    "        self.n_comps = n_comps\n",
    "        self.l1 = l1\n",
    "        self.loadings = None\n",
    "        self.hasFit = False\n",
    "\n",
    "    def fit(self, X, y = None, verbose = 0):\n",
    "\n",
    "        if verbose: \n",
    "            print(\"Progress based on max iterations:\")\n",
    "            pbar = tqdm(total = self.max_iter)\n",
    "\n",
    "        # Step 1: Setup first iteration\n",
    "        U, _, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "        A = Vt.T[:,:self.n_comps]\n",
    "        B = np.zeros((A[:,0].shape[0], self.n_comps))\n",
    "        XtX = X.T @ X\n",
    "        iter = 0\n",
    "        diff, diff_improve = 100, 100\n",
    "\n",
    "        # Loop of step 2 and 3 until convergence / maxiter:\n",
    "        while iter < self.max_iter and diff > self.tol and diff_improve > self.improve_tol:\n",
    "            B_old = np.copy(B)\n",
    "            \n",
    "            # Update B (step 2*)\n",
    "            input = A.T @ XtX\n",
    "            for i in range(self.n_comps):\n",
    "                B[:, i] = self._soft_threshold(input[i,:], 10)\n",
    "            \n",
    "            # Monitor change\n",
    "            diff_old = diff\n",
    "            diff = self._max_diff(B_old, B)\n",
    "            diff_improve = np.abs(diff - diff_old)\n",
    "\n",
    "            # Update A (step 3)\n",
    "            A_old = A    \n",
    "            Un, s, Vnt = np.linalg.svd(XtX @ B, full_matrices=False)\n",
    "            A = Un @ Vnt\n",
    "\n",
    "            if verbose: pbar.update(1)\n",
    "            iter = iter + 1\n",
    "        pbar.close()\n",
    "\n",
    "        # Normalize loadings after loop\n",
    "        B = self._normalize_mat(B)\n",
    "        self.loadings = B\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        return X @ self.loadings\n",
    "    \n",
    "    def _soft_threshold(self, vec, l1):\n",
    "        temp = np.maximum(0, (np.abs(vec) - l1 / 2))\n",
    "        return temp * np.sign(vec)\n",
    "\n",
    "    def _max_diff(self, X1, X2):\n",
    "        return np.max(np.abs(X1 - X2))\n",
    "\n",
    "    def _normalize_mat(self, X):\n",
    "        for i in range(X.shape[1]):\n",
    "            X[:,i] = X[:,i] / np.maximum(np.linalg.norm(X[:,i]), 1)\n",
    "        return X   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress based on max iterations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [00:29<00:38,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = Gene_SPCA()\n",
    "transform.fit(X, verbose = 1)\n",
    "traintest = transform.transform(data['golub']['none']['X_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get first k loadings of ordinary principal components\n",
    "U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "V = Vt.T\n",
    "D = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "D[:s.size, :s.size] = np.diag(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: solve elastic net problem for j in 1 ... k\n",
    "\n",
    "def objective_elastic_net(beta, alpha, X, l, l2):\n",
    "    assert len(beta) == len(alpha), \"shape of principal comp. vector alpha does not coincide with beta\"\n",
    "    return (alpha - beta).T @ X.T @ X @ (alpha - beta) + l * np.linalg.norm(beta) ** 2 + l2 * np.linalg.norm(beta)\n",
    "\n",
    "def soft_threshold(vec, l1):\n",
    "    temp = np.maximum(0, (np.abs(vec) - l1 / 2))\n",
    "    return temp * np.sign(vec)\n",
    "\n",
    "def max_diff(X1, X2):\n",
    "    return np.max(np.abs(X1 - X2))\n",
    "\n",
    "def normalize_mat(X):\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = X[:,i] / np.linalg.norm(X[:,i])\n",
    "    return X\n",
    "\n",
    "# For normal SPCA\n",
    "# B[:,i] = minimize(objective_elastic_net, np.zeros(B[:,i].shape[0]), args = (A[:,i], X, 1, 2)).x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1513.1375378889386\n",
      "69450\n",
      "1\n",
      "1.7448700991683381\n",
      "69441\n",
      "2\n",
      "1.3336661661349325\n",
      "69430\n",
      "3\n",
      "1.3243365202627047\n",
      "69440\n",
      "4\n",
      "1.3147965143171092\n",
      "69443\n",
      "5\n",
      "1.306580337606647\n",
      "69442\n",
      "6\n",
      "1.297287141508832\n",
      "69458\n",
      "7\n",
      "1.2889679095624587\n",
      "69462\n",
      "8\n",
      "1.282342662367256\n",
      "69460\n",
      "9\n",
      "1.2761621587582255\n",
      "69463\n",
      "10\n",
      "1.2688781972920253\n",
      "69468\n",
      "11\n",
      "1.261676639080207\n",
      "69458\n",
      "12\n",
      "1.254208358805073\n",
      "69459\n",
      "13\n",
      "1.2465486852736518\n",
      "69453\n",
      "14\n",
      "1.2397049254986854\n",
      "69434\n",
      "15\n",
      "1.232822754453096\n",
      "69438\n",
      "16\n",
      "1.2260402711665819\n",
      "69433\n",
      "17\n",
      "1.2186481138058411\n",
      "69423\n",
      "18\n",
      "1.2116439775413568\n",
      "69426\n",
      "19\n",
      "1.204619939615526\n",
      "69424\n",
      "20\n",
      "1.1979500276377735\n",
      "69424\n",
      "21\n",
      "1.192465491457554\n",
      "69417\n",
      "22\n",
      "1.187098650570661\n",
      "69406\n",
      "23\n",
      "1.1811105906828914\n",
      "69401\n",
      "24\n",
      "1.1739720547341363\n",
      "69392\n",
      "25\n",
      "1.1658345481362034\n",
      "69390\n",
      "26\n",
      "1.156860604379915\n",
      "69390\n",
      "27\n",
      "1.1475184051748073\n",
      "69384\n",
      "28\n",
      "1.138345763232735\n",
      "69377\n",
      "29\n",
      "1.1300102225294353\n",
      "69378\n",
      "30\n",
      "1.1224313496653977\n",
      "69385\n",
      "31\n",
      "1.1153783129547747\n",
      "69377\n",
      "32\n",
      "1.1089541093639923\n",
      "69383\n",
      "33\n",
      "1.1026896392392516\n",
      "69378\n",
      "34\n",
      "1.0964504133966528\n",
      "69373\n",
      "35\n",
      "1.091261696378588\n",
      "69370\n",
      "36\n",
      "1.085751246835997\n",
      "69371\n",
      "37\n",
      "1.080155405165307\n",
      "69375\n",
      "38\n",
      "1.0753299446148503\n",
      "69368\n",
      "39\n",
      "1.070824557805878\n",
      "69370\n",
      "40\n",
      "1.0658023575302877\n",
      "69370\n",
      "41\n",
      "1.060587600089164\n",
      "69367\n",
      "42\n",
      "1.0552097758911074\n",
      "69376\n",
      "43\n",
      "1.0496277574579835\n",
      "69369\n",
      "44\n",
      "1.044078702314664\n",
      "69365\n",
      "45\n",
      "1.0379830619145949\n",
      "69370\n",
      "46\n",
      "1.0315956636407648\n",
      "69366\n",
      "47\n",
      "1.0256958609341922\n",
      "69380\n",
      "48\n",
      "1.0207663247758845\n",
      "69383\n",
      "49\n",
      "1.0159922441320006\n",
      "69384\n",
      "50\n",
      "1.0100115388842\n",
      "69387\n",
      "51\n",
      "1.0041614109928716\n",
      "69385\n",
      "52\n",
      "0.998851558216515\n",
      "69388\n",
      "53\n",
      "0.9933428913730253\n",
      "69393\n",
      "54\n",
      "0.9883168521329182\n",
      "69385\n",
      "55\n",
      "0.9831218425008643\n",
      "69384\n",
      "56\n",
      "0.9783048000427499\n",
      "69394\n",
      "57\n",
      "0.9728963146225595\n",
      "69397\n",
      "58\n",
      "0.9676019182117983\n",
      "69404\n",
      "59\n",
      "0.9627425072738163\n",
      "69402\n",
      "60\n",
      "0.9584167010669944\n",
      "69410\n",
      "61\n",
      "0.9545758390619525\n",
      "69406\n",
      "62\n",
      "0.9506473443870362\n",
      "69402\n",
      "63\n",
      "0.946457778255656\n",
      "69405\n",
      "64\n",
      "0.9425752866941117\n",
      "69394\n",
      "65\n",
      "0.9388932477282772\n",
      "69391\n",
      "66\n",
      "0.9346732410980856\n",
      "69388\n",
      "67\n",
      "0.9300429838632986\n",
      "69397\n",
      "68\n",
      "0.9248760002510146\n",
      "69398\n",
      "69\n",
      "0.9200546187690293\n",
      "69394\n",
      "70\n",
      "0.9155206057893075\n",
      "69391\n",
      "71\n",
      "0.9110287483488015\n",
      "69393\n",
      "72\n",
      "0.9057821555058858\n",
      "69408\n",
      "73\n",
      "0.9007223016848585\n",
      "69417\n",
      "74\n",
      "0.8957536810090829\n",
      "69417\n",
      "75\n",
      "0.890737740385692\n",
      "69417\n",
      "76\n",
      "0.8860945788224015\n",
      "69418\n",
      "77\n",
      "0.8820953670465741\n",
      "69412\n",
      "78\n",
      "0.8781457183039834\n",
      "69402\n",
      "79\n",
      "0.8741567756178767\n",
      "69400\n",
      "80\n",
      "0.8697462245096155\n",
      "69402\n",
      "81\n",
      "0.8648269554138253\n",
      "69407\n",
      "82\n",
      "0.8595246390514255\n",
      "69408\n",
      "83\n",
      "0.8538002874472088\n",
      "69412\n",
      "84\n",
      "0.84819021849645\n",
      "69410\n",
      "85\n",
      "0.8425240449101974\n",
      "69413\n",
      "86\n",
      "0.8366128964547599\n",
      "69411\n",
      "87\n",
      "0.8314306601599171\n",
      "69417\n",
      "88\n",
      "0.8262705823571297\n",
      "69409\n",
      "89\n",
      "0.8215537106788\n",
      "69416\n",
      "90\n",
      "0.8168691634118321\n",
      "69417\n",
      "91\n",
      "0.792809855438918\n",
      "69422\n",
      "92\n",
      "0.7877782951986205\n",
      "69412\n",
      "93\n",
      "0.7832763959268618\n",
      "69403\n",
      "94\n",
      "0.7789125472386615\n",
      "69410\n",
      "95\n",
      "0.7742070733036712\n",
      "69413\n",
      "96\n",
      "0.7699499990220602\n",
      "69408\n",
      "97\n",
      "0.765638555484486\n",
      "69414\n",
      "98\n",
      "0.7613039782758619\n",
      "69416\n",
      "99\n",
      "0.7570128296951282\n",
      "69416\n",
      "100\n",
      "0.7527483120393015\n",
      "69405\n",
      "101\n",
      "0.7492914473377823\n",
      "69404\n",
      "102\n",
      "0.7454929829153798\n",
      "69417\n",
      "103\n",
      "0.7415679693821176\n",
      "69418\n",
      "104\n",
      "0.7568800142978516\n",
      "69424\n",
      "105\n",
      "0.7540733079720257\n",
      "69424\n",
      "106\n",
      "0.7514850272722242\n",
      "69410\n",
      "107\n",
      "0.7489239127081557\n",
      "69400\n",
      "108\n",
      "0.7464463226848146\n",
      "69405\n",
      "109\n",
      "0.7436854360224547\n",
      "69407\n",
      "110\n",
      "0.7405582715666696\n",
      "69403\n",
      "111\n",
      "0.7369472698998152\n",
      "69393\n",
      "112\n",
      "0.7329769881594377\n",
      "69398\n",
      "113\n",
      "0.728744102821663\n",
      "69404\n",
      "114\n",
      "0.7246778344971858\n",
      "69393\n",
      "115\n",
      "0.7209948936901789\n",
      "69378\n",
      "116\n",
      "0.7167308540165411\n",
      "69375\n",
      "117\n",
      "0.7122131778014769\n",
      "69380\n",
      "118\n",
      "0.7075276046724159\n",
      "69377\n",
      "119\n",
      "0.7027572398379505\n",
      "69381\n",
      "120\n",
      "0.6982124034194435\n",
      "69372\n",
      "121\n",
      "0.6935568906840253\n",
      "69361\n",
      "122\n",
      "0.6885088067120186\n",
      "69349\n",
      "123\n",
      "0.6831221823882849\n",
      "69347\n",
      "124\n",
      "0.677136527860938\n",
      "69341\n",
      "125\n",
      "0.6710052137557483\n",
      "69344\n",
      "126\n",
      "0.6647686719625234\n",
      "69343\n",
      "127\n",
      "0.6589515834647592\n",
      "69336\n",
      "128\n",
      "0.6534340225885487\n",
      "69343\n",
      "129\n",
      "0.6480950890187387\n",
      "69344\n",
      "130\n",
      "0.64314978241622\n",
      "69351\n",
      "131\n",
      "0.6386103820847246\n",
      "69355\n",
      "132\n",
      "0.6344987488773413\n",
      "69356\n",
      "133\n",
      "0.6302401610063306\n",
      "69348\n",
      "134\n",
      "0.6261858968310072\n",
      "69346\n",
      "135\n",
      "0.6220921689301591\n",
      "69345\n",
      "136\n",
      "0.6178236799508312\n",
      "69343\n",
      "137\n",
      "0.6135792906085804\n",
      "69354\n",
      "138\n",
      "0.6093841843735497\n",
      "69345\n",
      "139\n",
      "0.6053615514200921\n",
      "69349\n",
      "140\n",
      "0.6014507389423613\n",
      "69351\n",
      "141\n",
      "0.5973095391978198\n",
      "69350\n",
      "142\n",
      "0.5931636354954151\n",
      "69360\n",
      "143\n",
      "0.5884211807982709\n",
      "69357\n",
      "144\n",
      "0.5881397067164471\n",
      "69362\n",
      "145\n",
      "0.5891388181107686\n",
      "69363\n",
      "146\n",
      "0.5900831113849136\n",
      "69362\n",
      "147\n",
      "0.590614263229881\n",
      "69359\n",
      "148\n",
      "0.591059583145352\n",
      "69359\n",
      "149\n",
      "0.5914206587315505\n",
      "69350\n",
      "150\n",
      "0.5911755892113604\n",
      "69349\n",
      "151\n",
      "0.5906255572533894\n",
      "69363\n",
      "152\n",
      "0.5899394625273118\n",
      "69367\n",
      "153\n",
      "0.5892668364741098\n",
      "69357\n",
      "154\n",
      "0.5887842105474945\n",
      "69349\n",
      "155\n",
      "0.5879667670984929\n",
      "69344\n",
      "156\n",
      "0.5866063444422025\n",
      "69345\n",
      "157\n",
      "0.5854135684167758\n",
      "69340\n",
      "158\n",
      "0.584090030682809\n",
      "69342\n",
      "159\n",
      "0.5829323446254193\n",
      "69353\n",
      "160\n",
      "0.5821417830290017\n",
      "69354\n",
      "161\n",
      "0.5815257268392386\n",
      "69352\n",
      "162\n",
      "0.580976793152935\n",
      "69355\n",
      "163\n",
      "0.5803718772437563\n",
      "69345\n",
      "164\n",
      "0.5798169678651206\n",
      "69342\n",
      "165\n",
      "0.5786489637493872\n",
      "69347\n",
      "166\n",
      "0.5780220758407211\n",
      "69335\n",
      "167\n",
      "0.5775735995600613\n",
      "69335\n",
      "168\n",
      "0.576844338218379\n",
      "69338\n",
      "169\n",
      "0.5759340885983946\n",
      "69344\n",
      "170\n",
      "0.5747974938983731\n",
      "69344\n",
      "171\n",
      "0.5735616905442029\n",
      "69341\n",
      "172\n",
      "0.5725760731192295\n",
      "69348\n",
      "173\n",
      "0.5716338884524603\n",
      "69350\n",
      "174\n",
      "0.5707406227567091\n",
      "69352\n",
      "175\n",
      "0.5695788373069277\n",
      "69347\n",
      "176\n",
      "0.5686866029476363\n",
      "69353\n",
      "177\n",
      "0.5676741390527269\n",
      "69358\n",
      "178\n",
      "0.5671625248583965\n",
      "69361\n",
      "179\n",
      "0.5661898893692339\n",
      "69360\n",
      "180\n",
      "0.5650217362944616\n",
      "69352\n",
      "181\n",
      "0.5636986881917281\n",
      "69350\n",
      "182\n",
      "0.5622129491006973\n",
      "69356\n",
      "183\n",
      "0.5608533338726218\n",
      "69363\n",
      "184\n",
      "0.5598748125192117\n",
      "69376\n",
      "185\n",
      "0.5590634518713173\n",
      "69372\n",
      "186\n",
      "0.5580355415743696\n",
      "69367\n",
      "187\n",
      "0.5572990126019164\n",
      "69357\n",
      "188\n",
      "0.556483327804969\n",
      "69365\n",
      "189\n",
      "0.555380780946237\n",
      "69367\n",
      "190\n",
      "0.5543893879805069\n",
      "69365\n",
      "191\n",
      "0.5534478774626876\n",
      "69368\n",
      "192\n",
      "0.5524484684678299\n",
      "69377\n",
      "193\n",
      "0.5515140962475868\n",
      "69375\n",
      "194\n",
      "0.5505079048402735\n",
      "69377\n",
      "195\n",
      "0.5495042557377872\n",
      "69376\n",
      "196\n",
      "0.5489646302937246\n",
      "69383\n",
      "197\n",
      "0.5486406665861807\n",
      "69385\n",
      "198\n",
      "0.5483637328013202\n",
      "69384\n",
      "199\n",
      "0.5483428464488611\n",
      "69375\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "\n",
    "k = 10\n",
    "A = V[:,:k]\n",
    "B = np.zeros((A[:,0].shape[0], k))\n",
    "XtX = X.T @ X\n",
    "\n",
    "tol = 0.001\n",
    "maxiter = 200\n",
    "iter = 0\n",
    "diff = 10\n",
    "\n",
    "while iter < maxiter and diff > tol:\n",
    "\n",
    "    B_old = np.copy(B)\n",
    "\n",
    "    input = A.T @ XtX\n",
    "    for i in range(k):\n",
    "        x = input[i,:]\n",
    "        B[:, i] = soft_threshold(x, 10)\n",
    "    \n",
    "    diff = max_diff(B_old, B)\n",
    "\n",
    "    # Update A (step 3)\n",
    "    A_old = A    \n",
    "    Un, s, Vnt = np.linalg.svd(XtX @ B, full_matrices=False)\n",
    "    A = Un @ Vnt\n",
    "\n",
    "    print(iter)\n",
    "    print(diff)    \n",
    "    print(np.count_nonzero(B))\n",
    "\n",
    "    iter = iter + 1\n",
    "\n",
    "B = normalize_spca(B)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\VU_git\\vu-case-study-eds\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_auc_score, roc_curve, RocCurveDisplay, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "newX = X @ B\n",
    "testX = data['golub']['none']['X_test'] @ B\n",
    "y_train =  data['golub']['none']['y_train']\n",
    "y_test =  data['golub']['none']['y_test']\n",
    "\n",
    "clf = LogisticRegression(random_state= 2023)\n",
    "clf.fit(traintest, data['golub']['none']['y_train'])\n",
    "clf.score(transform.transform(data['golub']['none']['X_test']), data['golub']['none']['y_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 20)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7129)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "798b358ac2319934761a0de4f13ee9d5cebfbe5f460487494742ce99d4b4f7bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
