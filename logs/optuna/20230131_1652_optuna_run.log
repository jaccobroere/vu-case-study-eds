A new study created in memory with name: PCA_LR
Trial 0 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.7015781781815048, 'C': 0.21218511830445622}. Best is trial 0 with value: 0.7833333333333334.
Trial 1 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.5658642436793911, 'C': 0.039454198882909346}. Best is trial 0 with value: 0.7833333333333334.
Trial 2 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.3494399596032115, 'C': 0.043353731931900015}. Best is trial 0 with value: 0.7833333333333334.
Trial 3 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.7014919633487361, 'C': 0.9019789203205432}. Best is trial 0 with value: 0.7833333333333334.
Trial 4 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.6460758458315383, 'C': 0.2943072007523173}. Best is trial 0 with value: 0.7833333333333334.
Trial 5 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.549829014570048, 'C': 0.1544399773104682}. Best is trial 0 with value: 0.7833333333333334.
Trial 6 finished with value: 0.75 and parameters: {'l1_ratio': 0.559912672994197, 'C': 0.01615111216878308}. Best is trial 0 with value: 0.7833333333333334.
Trial 7 finished with value: 0.6166666666666667 and parameters: {'l1_ratio': 0.7498749036030993, 'C': 0.012782361686541937}. Best is trial 0 with value: 0.7833333333333334.
Trial 8 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.31814744863456124, 'C': 0.26120885868653004}. Best is trial 0 with value: 0.7833333333333334.
Trial 9 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.7434118873476072, 'C': 0.9079727091131031}. Best is trial 0 with value: 0.7833333333333334.
Trial 10 finished with value: 0.75 and parameters: {'l1_ratio': 0.9779356540525822, 'C': 0.09029266256959499}. Best is trial 0 with value: 0.7833333333333334.
Trial 11 finished with value: 0.8166666666666667 and parameters: {'l1_ratio': 0.027819478693038135, 'C': 0.05466266861412938}. Best is trial 11 with value: 0.8166666666666667.
Trial 12 finished with value: 0.8 and parameters: {'l1_ratio': 0.03370332777091369, 'C': 0.0779068320694622}. Best is trial 11 with value: 0.8166666666666667.
Trial 13 finished with value: 0.8 and parameters: {'l1_ratio': 0.0126807233321428, 'C': 0.07047477232519668}. Best is trial 11 with value: 0.8166666666666667.
Trial 14 finished with value: 0.8166666666666667 and parameters: {'l1_ratio': 0.03568659158196132, 'C': 0.03510314856947193}. Best is trial 11 with value: 0.8166666666666667.
Trial 15 finished with value: 0.8333333333333333 and parameters: {'l1_ratio': 0.13885407182342835, 'C': 0.02427808299201495}. Best is trial 15 with value: 0.8333333333333333.
Trial 16 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.17804503193610205, 'C': 0.021669675790355634}. Best is trial 15 with value: 0.8333333333333333.
Trial 17 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.1916341345457947, 'C': 0.023544220645130634}. Best is trial 15 with value: 0.8333333333333333.
Trial 18 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.16454267931193867, 'C': 0.011071549171897212}. Best is trial 15 with value: 0.8333333333333333.
Trial 19 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.39568830014609613, 'C': 0.022256714878778592}. Best is trial 15 with value: 0.8333333333333333.
Trial 20 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.20822222802561527, 'C': 0.026167645594118983}. Best is trial 15 with value: 0.8333333333333333.
Trial 21 finished with value: 0.8166666666666667 and parameters: {'l1_ratio': 0.19015878249294432, 'C': 0.01902618943020185}. Best is trial 15 with value: 0.8333333333333333.
Trial 22 finished with value: 0.8333333333333333 and parameters: {'l1_ratio': 0.13678409645988934, 'C': 0.02627005201543441}. Best is trial 15 with value: 0.8333333333333333.
Trial 23 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.12409071252460727, 'C': 0.010094027310250204}. Best is trial 15 with value: 0.8333333333333333.
Trial 24 finished with value: 0.8 and parameters: {'l1_ratio': 0.2505515115509119, 'C': 0.02839421430269845}. Best is trial 15 with value: 0.8333333333333333.
Trial 25 finished with value: 0.85 and parameters: {'l1_ratio': 0.11212768181276467, 'C': 0.017964383108354104}. Best is trial 25 with value: 0.85.
Trial 26 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.12572388978705584, 'C': 0.015549048005059938}. Best is trial 25 with value: 0.85.
Trial 27 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.26757172294256604, 'C': 0.014021941721911024}. Best is trial 25 with value: 0.85.
Trial 28 finished with value: 0.85 and parameters: {'l1_ratio': 0.08788642318553802, 'C': 0.016001384668060042}. Best is trial 25 with value: 0.85.
Trial 29 finished with value: 0.85 and parameters: {'l1_ratio': 0.09818753158355709, 'C': 0.017403565718851828}. Best is trial 25 with value: 0.85.
Trial 30 finished with value: 0.75 and parameters: {'l1_ratio': 0.42707239373938066, 'C': 0.015782722179337554}. Best is trial 25 with value: 0.85.
Trial 31 finished with value: 0.85 and parameters: {'l1_ratio': 0.08219873798174274, 'C': 0.016390865827978614}. Best is trial 25 with value: 0.85.
Trial 32 finished with value: 0.85 and parameters: {'l1_ratio': 0.07545640312104075, 'C': 0.011990248364238641}. Best is trial 25 with value: 0.85.
Trial 33 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.0818982606993862, 'C': 0.03599196501566762}. Best is trial 25 with value: 0.85.
Trial 34 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.08105112071042425, 'C': 0.010000230426208222}. Best is trial 25 with value: 0.85.
Trial 35 finished with value: 0.85 and parameters: {'l1_ratio': 0.0007366065223040896, 'C': 0.016828423277423774}. Best is trial 25 with value: 0.85.
Trial 36 finished with value: 0.8 and parameters: {'l1_ratio': 0.2560698779351818, 'C': 0.01888088964499446}. Best is trial 25 with value: 0.85.
Trial 37 finished with value: 0.8166666666666667 and parameters: {'l1_ratio': 0.07738063887594956, 'C': 0.04596926526430813}. Best is trial 25 with value: 0.85.
Trial 38 finished with value: 0.7666666666666667 and parameters: {'l1_ratio': 0.33623865446150314, 'C': 0.013862230746684925}. Best is trial 25 with value: 0.85.
Trial 39 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.22912459412248443, 'C': 0.02906804265067245}. Best is trial 25 with value: 0.85.
Trial 40 finished with value: 0.85 and parameters: {'l1_ratio': 0.11051865180355291, 'C': 0.019081035580587425}. Best is trial 25 with value: 0.85.
Trial 41 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.06934149050148854, 'C': 0.01238166361360518}. Best is trial 41 with value: 0.8666666666666666.
Trial 42 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.05350832836067376, 'C': 0.012871554013236135}. Best is trial 42 with value: 0.8666666666666668.
Trial 43 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.0018118366668429461, 'C': 0.012667025653125497}. Best is trial 42 with value: 0.8666666666666668.
Trial 44 finished with value: 0.85 and parameters: {'l1_ratio': 0.04211863922865631, 'C': 0.012639246505128165}. Best is trial 42 with value: 0.8666666666666668.
Trial 45 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.005475152649920302, 'C': 0.012503864149311877}. Best is trial 42 with value: 0.8666666666666668.
Trial 46 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.0009797427310205553, 'C': 0.01251280564828982}. Best is trial 42 with value: 0.8666666666666668.
Trial 47 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.0030784794146089846, 'C': 0.012360960423766495}. Best is trial 42 with value: 0.8666666666666668.
Trial 48 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.04473412132847552, 'C': 0.010210668039774768}. Best is trial 42 with value: 0.8666666666666668.
Trial 49 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.042970841125824236, 'C': 0.01032524089184128}. Best is trial 42 with value: 0.8666666666666668.
Trial 50 finished with value: 0.7833333333333334 and parameters: {'l1_ratio': 0.16710096536540703, 'C': 0.010932973110918296}. Best is trial 42 with value: 0.8666666666666668.
Trial 51 finished with value: 0.85 and parameters: {'l1_ratio': 0.05140879952355672, 'C': 0.01024357552691488}. Best is trial 42 with value: 0.8666666666666668.
Trial 52 finished with value: 0.85 and parameters: {'l1_ratio': 0.03809721259393817, 'C': 0.013651941238196507}. Best is trial 42 with value: 0.8666666666666668.
Trial 53 finished with value: 0.85 and parameters: {'l1_ratio': 0.050011469683514644, 'C': 0.013733872226674746}. Best is trial 42 with value: 0.8666666666666668.
Trial 54 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.15392541393539347, 'C': 0.01178399199875912}. Best is trial 42 with value: 0.8666666666666668.
Trial 55 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.039605840543766584, 'C': 0.010013540866136594}. Best is trial 42 with value: 0.8666666666666668.
Trial 56 finished with value: 0.85 and parameters: {'l1_ratio': 0.05131076299977946, 'C': 0.022264788782912884}. Best is trial 42 with value: 0.8666666666666668.
Trial 57 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.14819901778915145, 'C': 0.010467906046776849}. Best is trial 42 with value: 0.8666666666666668.
Trial 58 finished with value: 0.8166666666666667 and parameters: {'l1_ratio': 0.20098754957447207, 'C': 0.020316606846204274}. Best is trial 42 with value: 0.8666666666666668.
Trial 59 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.12199107234557059, 'C': 0.014737664425034257}. Best is trial 42 with value: 0.8666666666666668.
Trial 60 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.042800848159736705, 'C': 0.01000688258387913}. Best is trial 42 with value: 0.8666666666666668.
Trial 61 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.037986861942299145, 'C': 0.010259290751387297}. Best is trial 42 with value: 0.8666666666666668.
Trial 62 finished with value: 0.85 and parameters: {'l1_ratio': 0.05615377107852626, 'C': 0.010819789668429454}. Best is trial 42 with value: 0.8666666666666668.
Trial 63 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.034119871496464255, 'C': 0.014468129767722986}. Best is trial 42 with value: 0.8666666666666668.
Trial 64 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.10017904390007962, 'C': 0.01013852179466531}. Best is trial 42 with value: 0.8666666666666668.
Trial 65 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.1414920734196914, 'C': 0.01522371009939362}. Best is trial 42 with value: 0.8666666666666668.
Trial 66 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.06159028498009637, 'C': 0.011337169146456506}. Best is trial 42 with value: 0.8666666666666668.
Trial 67 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.030200089253698385, 'C': 0.01975372831571571}. Best is trial 42 with value: 0.8666666666666668.
Trial 68 finished with value: 0.8 and parameters: {'l1_ratio': 0.1767406302076935, 'C': 0.015938689107507696}. Best is trial 42 with value: 0.8666666666666668.
Trial 69 finished with value: 0.8333333333333333 and parameters: {'l1_ratio': 0.10945231710813286, 'C': 0.010059238937309638}. Best is trial 42 with value: 0.8666666666666668.
Trial 70 finished with value: 0.85 and parameters: {'l1_ratio': 0.06806702786426366, 'C': 0.0172982279376113}. Best is trial 42 with value: 0.8666666666666668.
Trial 71 finished with value: 0.85 and parameters: {'l1_ratio': 0.026367273286669296, 'C': 0.012256666365504449}. Best is trial 42 with value: 0.8666666666666668.
Trial 72 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.1091829232613851, 'C': 0.013566621998972636}. Best is trial 42 with value: 0.8666666666666668.
Trial 73 finished with value: 0.85 and parameters: {'l1_ratio': 0.018436034306879023, 'C': 0.011674897776741328}. Best is trial 42 with value: 0.8666666666666668.
Trial 74 finished with value: 0.85 and parameters: {'l1_ratio': 0.07170802115918104, 'C': 0.013631922488484351}. Best is trial 42 with value: 0.8666666666666668.
Trial 75 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.0008874602333652018, 'C': 0.011737110136029275}. Best is trial 42 with value: 0.8666666666666668.
Trial 76 finished with value: 0.85 and parameters: {'l1_ratio': 0.13783504931567847, 'C': 0.017666660695455715}. Best is trial 42 with value: 0.8666666666666668.
Trial 77 finished with value: 0.85 and parameters: {'l1_ratio': 0.09410059159023121, 'C': 0.023242329391938262}. Best is trial 42 with value: 0.8666666666666668.
Trial 78 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.03666703895854151, 'C': 0.015066736172516894}. Best is trial 42 with value: 0.8666666666666668.
Trial 79 finished with value: 0.8333333333333333 and parameters: {'l1_ratio': 0.09021445653009857, 'C': 0.010058623416479187}. Best is trial 42 with value: 0.8666666666666668.
Trial 80 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.1270007740252922, 'C': 0.01282486653254405}. Best is trial 42 with value: 0.8666666666666668.
Trial 81 finished with value: 0.85 and parameters: {'l1_ratio': 0.019846611065168846, 'C': 0.011731348177143296}. Best is trial 42 with value: 0.8666666666666668.
Trial 82 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.0028550246393461154, 'C': 0.013315198301957685}. Best is trial 42 with value: 0.8666666666666668.
Trial 83 finished with value: 0.85 and parameters: {'l1_ratio': 0.050202627351666494, 'C': 0.015716498410056755}. Best is trial 42 with value: 0.8666666666666668.
Trial 84 finished with value: 0.85 and parameters: {'l1_ratio': 0.06986250478293725, 'C': 0.011265011957883925}. Best is trial 42 with value: 0.8666666666666668.
Trial 85 finished with value: 0.85 and parameters: {'l1_ratio': 0.017589931177830774, 'C': 0.02018956342811087}. Best is trial 42 with value: 0.8666666666666668.
Trial 86 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.16532724642529675, 'C': 0.012833639983283305}. Best is trial 42 with value: 0.8666666666666668.
Trial 87 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.061024640519102794, 'C': 0.01768711887619244}. Best is trial 42 with value: 0.8666666666666668.
Trial 88 finished with value: 0.8666666666666666 and parameters: {'l1_ratio': 0.09068867978351877, 'C': 0.014569032917283538}. Best is trial 42 with value: 0.8666666666666668.
Trial 89 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.024004290059972646, 'C': 0.011309389880985524}. Best is trial 42 with value: 0.8666666666666668.
Trial 90 finished with value: 0.8333333333333333 and parameters: {'l1_ratio': 0.11992072123089137, 'C': 0.010856984838183559}. Best is trial 42 with value: 0.8666666666666668.
Trial 91 finished with value: 0.85 and parameters: {'l1_ratio': 0.028601006619958274, 'C': 0.012408496537769828}. Best is trial 42 with value: 0.8666666666666668.
Trial 92 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.05004523223375146, 'C': 0.011305873989670227}. Best is trial 42 with value: 0.8666666666666668.
Trial 93 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.046665490527868676, 'C': 0.011291083781280055}. Best is trial 42 with value: 0.8666666666666668.
Trial 94 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.08081533116323245, 'C': 0.01002866446476506}. Best is trial 42 with value: 0.8666666666666668.
Trial 95 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.05055472315393733, 'C': 0.011312246262126345}. Best is trial 42 with value: 0.8666666666666668.
Trial 96 finished with value: 0.8666666666666668 and parameters: {'l1_ratio': 0.05198751630645751, 'C': 0.011180354429225058}. Best is trial 42 with value: 0.8666666666666668.
Trial 97 finished with value: 0.85 and parameters: {'l1_ratio': 0.03983061591168813, 'C': 0.0143455965615074}. Best is trial 42 with value: 0.8666666666666668.
Trial 98 finished with value: 0.8166666666666668 and parameters: {'l1_ratio': 0.10243140234534096, 'C': 0.011224499800233273}. Best is trial 42 with value: 0.8666666666666668.
Trial 99 finished with value: 0.8333333333333334 and parameters: {'l1_ratio': 0.1439032631824683, 'C': 0.01596070417819443}. Best is trial 42 with value: 0.8666666666666668.
A new study created in memory with name: SPCA_LR
Trial 0 failed with parameters: {'l1_ratio': 0.9102571818668926, 'C': 0.026515293966302044} because of the following error: ValueError('\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score=\'raise\'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1196, in fit\n    X, y = self._validate_data(\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/base.py", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1104, in check_X_y\n    X = check_array(\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 919, in check_array\n    _assert_all_finite(\n  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n').
Traceback (most recent call last):
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
  File "/Users/jacco/Documents/repos/vu-case-study-eds/src/helpers/config/hyperparameters.py", line 63, in <lambda>
    lambda trial: self._objective(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/src/helpers/config/hyperparameters.py", line 39, in _objective
    cv_score = cross_val_score(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 515, in cross_val_score
    cv_results = cross_validate(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py", line 1196, in fit
    X, y = self._validate_data(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/base.py", line 554, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1104, in check_X_y
    X = check_array(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 919, in check_array
    _assert_all_finite(
  File "/Users/jacco/Documents/repos/vu-case-study-eds/venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

Trial 0 failed with value None.
